import requests
import csv
import time
from bs4 import BeautifulSoup

csv_file = open('scrapper2.csv', 'w')
csv_writer = csv.writer(csv_file)
csv_writer.writerow(['User', 'PushDate', 'Changeset' , 'Author' , 'BugID' ])

for i in range(1,1771):
    url = requests.get("https://hg.mozilla.org/comm-central/pushloghtml/" + str(i) + "/")
    soup = BeautifulSoup(url.text, 'lxml')

    for item in soup.find_all('tr', class_='pushlogentry'):
            try:
                head = item.td.text
                headline = head.split(' ')[0][:-3]
                print(headline)

                push_date = head.split(' ')[0][-3:]
                try:
                    date2 = head.split(' ', 1)[1]
                    date = push_date + date2
                    print(date)
                except:
                    AttributeError

                commit = item.a.text
                print(commit)

                author = item.strong.text
                print(author)

                bug = item.strong.a.text
                bid = bug.split(' ') [1]
                print(bid)
            except:AttributeError

            csv_writer.writerow([headline, date, commit, author, bid])
    time.sleep(3)

csv_file.close()






